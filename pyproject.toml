[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "video2md"
version = "0.2.0"
description = "Video2MD - AI toolkit for converting videos to structured markdown summaries"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "AI Agent Tools"},
]
keywords = ["whisper", "transcription", "ai-agent", "video-conversion", "chinese-text"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Multimedia :: Sound/Audio :: Conversion",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

dependencies = [
    "requests>=2.31.0",
    "python-dotenv>=1.0.0",
    "zhconv>=1.4.3",
    "mcp[cli]>=1.5.0",
    "openai>=2.6.1",
    "openai-agents>=0.4.2",
    "jinja2>=3.1.0",
    "gradio>=5.49.1",
    "faster-whisper>=1.1.1",
]

[project.urls]
Homepage = "https://github.com/your-username/video2md"
Repository = "https://github.com/your-username/video2md"
Issues = "https://github.com/your-username/video2md/issues"

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0", 
    "flake8>=6.0.0",
    "mypy>=1.0.0",
]
test = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
]
gpu = [
    # For GPU acceleration with CUDA
    # PyTorch with CUDA support must be installed separately due to special index URL requirement
    # 
    # For CUDA 12.x (12.4 and newer compatible, including 12.9):
    # uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
    # 
    # For CUDA 11.8:
    # uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    # 
    # After installing PyTorch, faster-whisper will automatically use GPU if available
]
mcp-servers = [
    # Preinstall these to avoid `uvx` resolving at runtime (Python 3.11+)
    "mcp-server-fetch>=0 ; python_version >= '3.11'",
    "serper-mcp-server>=0 ; python_version >= '3.11'",
]

[project.scripts]
video2md-whisper-client = "video2md.clients.whisper_client:main"
video2md-openai-transcribe-client = "video2md.clients.openai_transcribe_client:main"
video2md-video-converter = "video2md.tools.video_converter_tool:main"
video2md-chinese-converter = "video2md.tools.chinese_converter_tool:main"
video2md-transcript-converter = "video2md.utils.transcript_converter:main"
video2md-whisper-server = "video2md.server.whisper_server:main"
video2md-openai-transcribe-server = "video2md.server.openai_transcribe_server:main"

[tool.setuptools.packages.find]
where = ["src"]
include = ["video2md*"]

[tool.setuptools.package-dir]
"" = "src"

[tool.black]
line-length = 100
target-version = ['py310']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "--cov=src --cov-report=html --cov-report=term"
